<!doctype html><html lang=en-us><head><title>Snippy: An AI Assistant With Eyes // TimDbg</title>
<link rel="shortcut icon" href=WinDbg.ico><meta charset=utf-8><meta name=generator content="Hugo 0.129.0"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Tim Misiak"><meta name=description content><link rel=stylesheet href=/css/main.min.4a7ec8660f9a44b08c4da97c5f2e31b1192df1d4d0322e65c0dbbc6ecb1b863f.css><link rel=stylesheet href=/custom.css><script async src="https://www.googletagmanager.com/gtag/js?id=G-ZF3NN3CLRX"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-ZF3NN3CLRX")}</script><meta name=twitter:card content="summary"><meta name=twitter:title content="Snippy: An AI Assistant With Eyes"><meta name=twitter:description content="While I no longer work on WinDbg, I still spend a lot of time thinking about how to make tools so people can build things faster. With WinDbg, I tried to do that by putting more debugging power at people’s fingertips in a way that was easier to use. Recently, everyone is looking for ways to use LLMs to build things faster. But for most people using something like ChatGPT means pasting text back and forth between your different tools."><meta property="og:url" content="/posts/snippy-assistant-with-eyes/"><meta property="og:site_name" content="TimDbg"><meta property="og:title" content="Snippy: An AI Assistant With Eyes"><meta property="og:description" content="While I no longer work on WinDbg, I still spend a lot of time thinking about how to make tools so people can build things faster. With WinDbg, I tried to do that by putting more debugging power at people’s fingertips in a way that was easier to use. Recently, everyone is looking for ways to use LLMs to build things faster. But for most people using something like ChatGPT means pasting text back and forth between your different tools."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-04-21T10:47:33-07:00"><meta property="article:modified_time" content="2024-04-21T10:47:33-07:00"><link rel=alternate type=application/rss+xml href=/index.xml title=TimDbg></head><body><header class=app-header><a href=/><img class=app-header-avatar src=/avatar.jpg alt="Tim Misiak"></a><h1>TimDbg</h1><nav class=app-header-menu><a class=app-header-menu-item href=/about/>About</a>
-
<a class=app-header-menu-item href=/tags/>Tags</a></nav><p>The art and science of debugging. And other stuff like that. From a former developer on WinDbg and the VMware hypervisor.</p><div class=app-header-social><a href=https://github.com/timmisiak target=_blank rel="noreferrer noopener"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-github"><title>Github</title><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg>
</a><a href=https://twitter.com/timmisiak target=_blank rel="noreferrer noopener"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-twitter"><title>Twitter</title><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg>
</a><a href=https://www.youtube.com/channel/UCyQ7p63-9V9PZJvgHLKgsaw target=_blank rel="noreferrer noopener"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-youtube"><title>YouTube</title><path d="M22.54 6.42a2.78 2.78.0 00-1.94-2C18.88 4 12 4 12 4s-6.88.0-8.6.46a2.78 2.78.0 00-1.94 2A29 29 0 001 11.75a29 29 0 00.46 5.33A2.78 2.78.0 003.4 19c1.72.46 8.6.46 8.6.46s6.88.0 8.6-.46a2.78 2.78.0 001.94-2 29 29 0 00.46-5.25 29 29 0 00-.46-5.33z"/><polygon points="9.75 15.02 15.5 11.75 9.75 8.48 9.75 15.02"/></svg></a></div></header><main class=app-container><article class=post><header class=post-header><h1 class=post-title>Snippy: An AI Assistant With Eyes</h1><div class=post-meta><div><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar"><title>calendar</title><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>
Apr 21, 2024</div><div><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock"><title>clock</title><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg>
7 min read</div></div></header><div class=post-content><p>While I no longer work on WinDbg, I still spend a lot of time thinking about how to make tools so people can build things faster. With WinDbg, I tried to do that by putting more debugging power at people&rsquo;s fingertips in a way that was easier to use. Recently, everyone is looking for ways to use LLMs to build things faster. But for most people using something like ChatGPT means pasting text back and forth between your different tools. We&rsquo;ve seen some better integrations with tooling like in VS Code, but I think there are still a ton of tools where an LLM can be useful but there&rsquo;s just no &ldquo;glue&rdquo; connecting it to your apps.</p><p>At <a href=https://augmend.com>Augmend</a>, we think that giving an AI assistant &ldquo;eyes&rdquo; into what you&rsquo;re doing can solve some of these problems. When we saw the demo that <a href="https://news.ycombinator.com/item?id=38203104">Suneel Matham had for sharing your screen with GPT-4</a>, we knew we wanted to implement our own version, and it was a great chance to use our cross-platform screen capture Rust crate, <a href=https://crates.io/crates/crabgrab>CrabGrab</a>. We built a new screen-sharing GPT assistant with CrabGrab, and we called it <a href=https://github.com/AugmendTech/Snippy/>Snippy</a>! We&rsquo;ve made both CrabGrab and Snippy open source under MIT or Apache-2.0, so I&rsquo;d love to see folks try these and make their own versions.</p><h1 id=demo>Demo</h1><p>First, a quick demo of what Snippy can do, and then I&rsquo;ll talk about how we built it. If you want to follow along, just clone the repo and run <code>cargo run</code> on Windows or macOS. When you first run Snippy, you&rsquo;ll see a prompt for your OpenAI API key.</p><p><img src=/snippy_api_key.png alt="Enter your API key"></p><p>After that, you can pick a window to &ldquo;chat&rdquo; with.</p><p><img src=/snippy_pick_window.png alt="Pick a window"></p><p>From there, you can start a &ldquo;chat&rdquo; where each message will include a screenshot of your app. This uses GPT-4 with vision, which is powerful enough to understand the text on the screen as well as the application you&rsquo;re using. (Under the hood you could swap this out with <a href=https://llava-vl.github.io/>LLaVA</a> or other multimodal LLMs)</p><p><img src=/snippy_chat_cmd.png alt="Chat with an app"></p><p>Besides just reading text, an LLM can also use context cues from what you&rsquo;re looking at to give correct answers for questions that would otherwise be ambiguous. Here I just asked how to get the disassembly of a function but didn&rsquo;t tell GPT what debugger I was using. It &ldquo;sees&rdquo; that I&rsquo;m using WinDbg and gives the correct disassembly command! Without that context, ChatGPT usually tells me to use objdump or gdb.</p><p><img src=/snippy_windbg.png alt="Questions with context!"></p><h1 id=how-it-works>How it works</h1><p>The code for Snippy is fairly simple, and uses three main pieces of tech. First, for the UI we&rsquo;re using <a href=https://tauri.app/>Tauri</a>. I&rsquo;m a big fan of Tauri, because it&rsquo;s easy to use, low overhead, and cross-platform. It also makes it very easy for JavaScript UI code to talk to Rust code, which is great because that lets us use our cross-platform screen capture crate called CrabGrab for grabbing screenshots of applications. Finally, we make a base64 encoded PNG along with our system prompt and send it to GPT-4.</p><h2 id=tauri>Tauri</h2><p>Our rust entrypoint just sets up our Tauri window with the set of Rust functions that we want to be callable from JS as part of the setup.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span><span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>main</span>() {
</span></span><span style=display:flex><span>	tauri::Builder::default()
</span></span><span style=display:flex><span>		.invoke_handler(tauri::generate_handler![
</span></span><span style=display:flex><span>			get_windows,
</span></span><span style=display:flex><span>			begin_capture,
</span></span><span style=display:flex><span>			end_capture,
</span></span><span style=display:flex><span>			send_message,
</span></span><span style=display:flex><span>			has_api_key,
</span></span><span style=display:flex><span>			set_api_key,
</span></span><span style=display:flex><span>		])
</span></span><span style=display:flex><span>		.setup(<span style=color:#f92672>|</span>app<span style=color:#f92672>|</span> {
</span></span><span style=display:flex><span>			<span style=color:#66d9ef>let</span> main_window <span style=color:#f92672>=</span> app.get_window(<span style=color:#e6db74>&#34;main&#34;</span>).expect(<span style=color:#e6db74>&#34;Expected app to have main window&#34;</span>);
</span></span><span style=display:flex><span>			<span style=color:#75715e>//main_window.open_devtools();
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>			Ok(())
</span></span><span style=display:flex><span>		})
</span></span><span style=display:flex><span>		.run(tauri::generate_context!())
</span></span><span style=display:flex><span>		.expect(<span style=color:#e6db74>&#34;error while running tauri application&#34;</span>);
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p><a href=https://github.com/AugmendTech/cggui/blob/main/src-tauri/src/main.rs#L205>main.rs on GitHub</a></p><p>From there the JS side of the code will drive most of the experience. When the document is loaded, we kick off the process by checking if an API key is available and showing that prompt, and calling the rust get_windows code to enumerate thumbnails.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-js data-lang=js><span style=display:flex><span>document.<span style=color:#a6e22e>addEventListener</span>(<span style=color:#e6db74>&#34;DOMContentLoaded&#34;</span>, <span style=color:#66d9ef>async</span> (<span style=color:#a6e22e>e</span>) =&gt; {
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Skipping lots of vanilla JS DOM stuff here...
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> <span style=color:#a6e22e>has_key</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> window.<span style=color:#a6e22e>__TAURI__</span>.<span style=color:#a6e22e>invoke</span>(<span style=color:#e6db74>&#34;has_api_key&#34;</span>);
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> (<span style=color:#f92672>!</span><span style=color:#a6e22e>has_key</span>) {
</span></span><span style=display:flex><span>        document.<span style=color:#a6e22e>getElementById</span>(<span style=color:#e6db74>&#34;config-panel-outer&#34;</span>).<span style=color:#a6e22e>hidden</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>false</span>;
</span></span><span style=display:flex><span>        document.<span style=color:#a6e22e>getElementById</span>(<span style=color:#e6db74>&#34;tile-container-outer&#34;</span>).<span style=color:#a6e22e>hidden</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>true</span>;
</span></span><span style=display:flex><span>        document.<span style=color:#a6e22e>getElementById</span>(<span style=color:#e6db74>&#34;snippy-text&#34;</span>).<span style=color:#a6e22e>innerText</span> <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;Before we can chat, we need to set up a few things.&#34;</span>;
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> <span style=color:#a6e22e>windows_json_string</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> window.<span style=color:#a6e22e>__TAURI__</span>.<span style=color:#a6e22e>invoke</span>(<span style=color:#e6db74>&#34;get_windows&#34;</span>, {<span style=color:#a6e22e>req</span><span style=color:#f92672>:</span> <span style=color:#ae81ff>1</span>});
</span></span><span style=display:flex><span>});
</span></span></code></pre></div><p><a href=https://github.com/AugmendTech/cggui/blob/main/src/main.js>main.js on GitHub</a></p><h2 id=crabgrab>CrabGrab</h2><p>Back in the rust implementation of get_windows, we see it call into CrabGrab to enumerate windows. We&rsquo;ll generate an ID for each window so we can get back to the <code>CapturableWindow</code> that CrabGrab gives us.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span><span style=color:#75715e>#[tauri::command]</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>get_windows</span>(app: <span style=color:#a6e22e>AppHandle</span>, req: <span style=color:#66d9ef>i32</span>) -&gt; String {
</span></span><span style=display:flex><span>    <span style=color:#75715e>// We set up some filters for the windows to grab only things that look like applications
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>	<span style=color:#66d9ef>let</span> filter <span style=color:#f92672>=</span> CapturableContentFilter {
</span></span><span style=display:flex><span>		windows: Some(CapturableWindowFilter {
</span></span><span style=display:flex><span>			desktop_windows: <span style=color:#a6e22e>false</span>,
</span></span><span style=display:flex><span>			onscreen_only: <span style=color:#a6e22e>true</span>
</span></span><span style=display:flex><span>		}),
</span></span><span style=display:flex><span>		displays: <span style=color:#a6e22e>false</span>,
</span></span><span style=display:flex><span>	};
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// We create a CrabGrab CapturableContent and use our filter to get the list of windows we want to show the user
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>	<span style=color:#66d9ef>let</span> content <span style=color:#f92672>=</span> CapturableContent::new(filter).<span style=color:#66d9ef>await</span>.unwrap();
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>let</span> window_list: Vec<span style=color:#f92672>&lt;</span>_<span style=color:#f92672>&gt;</span> <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>		<span style=color:#66d9ef>let</span> <span style=color:#66d9ef>mut</span> window_map <span style=color:#f92672>=</span> <span style=color:#66d9ef>WINDOW_MAP</span>.lock();
</span></span><span style=display:flex><span>		<span style=color:#66d9ef>for</span> window <span style=color:#66d9ef>in</span> content.windows() {
</span></span><span style=display:flex><span>			<span style=color:#66d9ef>if</span> <span style=color:#f92672>!</span>window_map.contains_key(<span style=color:#f92672>&amp;</span>window) {
</span></span><span style=display:flex><span>				<span style=color:#66d9ef>let</span> id <span style=color:#f92672>=</span> <span style=color:#66d9ef>WINDOW_ID_COUNTER</span>.fetch_add(<span style=color:#ae81ff>1</span>, atomic::Ordering::SeqCst);
</span></span><span style=display:flex><span>				window_map.insert(window, id);
</span></span><span style=display:flex><span>			}
</span></span><span style=display:flex><span>		};
</span></span><span style=display:flex><span>		window_map.iter().map(<span style=color:#f92672>|</span>(window, id)<span style=color:#f92672>|</span> (window.clone(), <span style=color:#f92672>*</span>id)).collect()
</span></span><span style=display:flex><span>	};
</span></span></code></pre></div><p>For each window, we scale it down and make it a base64-encoded PNG (There are better ways of sending images to the JS side, but this way is fairly concise and the same as how we&rsquo;ll send the images to the language model). The information for each window found is sent back via a Tauri event called &ldquo;window_found&rdquo; along with the title and an ID.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span>	<span style=color:#66d9ef>for</span> (window, id) <span style=color:#66d9ef>in</span> window_list.iter() {
</span></span><span style=display:flex><span>		<span style=color:#66d9ef>let</span> screenshot_config <span style=color:#f92672>=</span> CaptureConfig::with_window(window.clone(), CapturePixelFormat::Bgra8888).unwrap();
</span></span><span style=display:flex><span>		<span style=color:#66d9ef>let</span> screenshot_task <span style=color:#f92672>=</span> take_screenshot(screenshot_config);
</span></span><span style=display:flex><span>		<span style=color:#66d9ef>let</span> screenshot_result <span style=color:#f92672>=</span> timeout(Duration::from_millis(<span style=color:#ae81ff>250</span>), screenshot_task).<span style=color:#66d9ef>await</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>		<span style=color:#66d9ef>let</span> screenshot <span style=color:#f92672>=</span> <span style=color:#66d9ef>match</span> screenshot_result {
</span></span><span style=display:flex><span>			Ok(output) <span style=color:#f92672>=&gt;</span> output,
</span></span><span style=display:flex><span>			_ <span style=color:#f92672>=&gt;</span> <span style=color:#66d9ef>continue</span>
</span></span><span style=display:flex><span>		};
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>		<span style=color:#66d9ef>if</span> <span style=color:#66d9ef>let</span> Ok(Ok(FrameBitmap::BgraUnorm8x4(image_bitmap_bgra8888))) <span style=color:#f92672>=</span> screenshot.map(<span style=color:#f92672>|</span>frame<span style=color:#f92672>|</span> frame.get_bitmap()) {
</span></span><span style=display:flex><span>			<span style=color:#66d9ef>let</span> image_base64 <span style=color:#f92672>=</span> make_scaled_base64_png_from_bitmap(image_bitmap_bgra8888, <span style=color:#ae81ff>300</span>, <span style=color:#ae81ff>200</span>);
</span></span><span style=display:flex><span>			<span style=color:#66d9ef>let</span> item <span style=color:#f92672>=</span> Item {
</span></span><span style=display:flex><span>				id: <span style=color:#f92672>*</span>id,
</span></span><span style=display:flex><span>				thumbnail: <span style=color:#a6e22e>image_base64</span>,
</span></span><span style=display:flex><span>				title: <span style=color:#a6e22e>window</span>.title(),
</span></span><span style=display:flex><span>				req
</span></span><span style=display:flex><span>			};
</span></span><span style=display:flex><span>			<span style=color:#66d9ef>let</span> item_json <span style=color:#f92672>=</span> serde_json::to_string(<span style=color:#f92672>&amp;</span>item).unwrap();
</span></span><span style=display:flex><span>			app.emit_all(<span style=color:#e6db74>&#34;window_found&#34;</span>, item).unwrap();
</span></span><span style=display:flex><span>		}
</span></span><span style=display:flex><span>	}
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>The JS side subscribes to this event and creates an HTML element for each window that was found. When a user clicks on a specific window, we start capturing the window using the CrabGrab <code>CaptureStream</code>, which just takes a callback function that is called for each video frame captured. For our purposes here, we&rsquo;ll just use this for grabbing individual frames as needed, but you could also take these frames and run it through a video encoder, like we do in the full Augmend client.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span><span style=color:#75715e>#[tauri::command]</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>begin_capture</span>(app_handle: <span style=color:#a6e22e>tauri</span>::AppHandle, window_id: <span style=color:#66d9ef>u64</span>) -&gt; Result<span style=color:#f92672>&lt;</span>(), String<span style=color:#f92672>&gt;</span> {
</span></span><span style=display:flex><span>    <span style=color:#75715e>// First we need to map the generated window ID back to the CapturableWindow from CrabGrab
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>	<span style=color:#66d9ef>let</span> <span style=color:#66d9ef>mut</span> active_stream <span style=color:#f92672>=</span> <span style=color:#66d9ef>ACTIVE_STREAM</span>.lock();
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>let</span> window_map <span style=color:#f92672>=</span> <span style=color:#66d9ef>WINDOW_MAP</span>.lock();
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>for</span> (window, id) <span style=color:#66d9ef>in</span> window_map.iter() {
</span></span><span style=display:flex><span>		<span style=color:#66d9ef>if</span> <span style=color:#f92672>*</span>id <span style=color:#f92672>==</span> window_id {
</span></span><span style=display:flex><span>			<span style=color:#66d9ef>let</span> config <span style=color:#f92672>=</span> CaptureConfig::with_window(window.clone(), CapturePixelFormat::Bgra8888)
</span></span><span style=display:flex><span>				.map_err(<span style=color:#f92672>|</span>error<span style=color:#f92672>|</span> error.to_string())<span style=color:#f92672>?</span>;
</span></span><span style=display:flex><span>			<span style=color:#66d9ef>let</span> stream <span style=color:#f92672>=</span> CaptureStream::new(config, <span style=color:#f92672>|</span>event_result<span style=color:#f92672>|</span> {
</span></span><span style=display:flex><span>                <span style=color:#75715e>// This gets called for each frame captured from the window.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>				<span style=color:#66d9ef>match</span> event_result {
</span></span><span style=display:flex><span>					Ok(StreamEvent::Video(frame)) <span style=color:#f92672>=&gt;</span> {
</span></span><span style=display:flex><span>						<span style=color:#66d9ef>let</span> <span style=color:#66d9ef>mut</span> frame_req <span style=color:#f92672>=</span> <span style=color:#66d9ef>FRAME_REQUEST</span>.lock();
</span></span><span style=display:flex><span>						<span style=color:#66d9ef>if</span> <span style=color:#66d9ef>let</span> Some(req) <span style=color:#f92672>=</span> frame_req.take() {
</span></span><span style=display:flex><span>							req.send(frame).unwrap();
</span></span><span style=display:flex><span>						}
</span></span><span style=display:flex><span>					},
</span></span><span style=display:flex><span>					_ <span style=color:#f92672>=&gt;</span> {}
</span></span><span style=display:flex><span>				}
</span></span></code></pre></div><h2 id=gpt>GPT</h2><p>When a user sends a message, Snippy grabs a frame from the current application and encodes it as a base64 PNG. Then it includes that PNG along with a system prompt and sends it off to the OpenAI endpoint. The result gets passed back to the JavaScript side where some HTML elements are created for the chat message.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span><span style=color:#66d9ef>pub</span> <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>send_request</span>(msg: String, base64_png: String) -&gt; Result<span style=color:#f92672>&lt;</span>String, String<span style=color:#f92672>&gt;</span> {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> prompt <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;You are a helpful assistant named &#39;Snippy&#39; in the style of &#39;Clippy&#39; from Microsoft Office. </span><span style=color:#ae81ff>\</span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>You can see the current window that the user is looking at. You can answer questions the user has about the current window. </span><span style=color:#ae81ff>\</span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>If the user seems to have no specific question, feel free to offer advice on what they are currently looking at, but try to be concise. </span><span style=color:#ae81ff>\</span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>&#34;</span>;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> body <span style=color:#f92672>=</span> json!({
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;model&#34;</span>: <span style=color:#e6db74>&#34;gpt-4-turbo&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;messages&#34;</span>: [
</span></span><span style=display:flex><span>            {
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#34;role&#34;</span>: <span style=color:#e6db74>&#34;system&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#34;content&#34;</span>: [
</span></span><span style=display:flex><span>                    {
</span></span><span style=display:flex><span>                        <span style=color:#e6db74>&#34;type&#34;</span>: <span style=color:#e6db74>&#34;text&#34;</span>,
</span></span><span style=display:flex><span>                        <span style=color:#e6db74>&#34;text&#34;</span>: <span style=color:#a6e22e>prompt</span>
</span></span><span style=display:flex><span>                    }
</span></span><span style=display:flex><span>                ]
</span></span><span style=display:flex><span>            },
</span></span><span style=display:flex><span>            {
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#34;role&#34;</span>: <span style=color:#e6db74>&#34;user&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#e6db74>&#34;content&#34;</span>: [
</span></span><span style=display:flex><span>                    {
</span></span><span style=display:flex><span>                        <span style=color:#e6db74>&#34;type&#34;</span>: <span style=color:#e6db74>&#34;text&#34;</span>,
</span></span><span style=display:flex><span>                        <span style=color:#e6db74>&#34;text&#34;</span>: <span style=color:#a6e22e>msg</span>
</span></span><span style=display:flex><span>                    },
</span></span><span style=display:flex><span>                    {
</span></span><span style=display:flex><span>                        <span style=color:#e6db74>&#34;type&#34;</span>: <span style=color:#e6db74>&#34;image_url&#34;</span>,
</span></span><span style=display:flex><span>                        <span style=color:#e6db74>&#34;image_url&#34;</span>: {
</span></span><span style=display:flex><span>                            <span style=color:#e6db74>&#34;url&#34;</span>: <span style=color:#a6e22e>format</span><span style=color:#f92672>!</span>(<span style=color:#e6db74>&#34;data:image/png;base64,{}&#34;</span>, base64_png)
</span></span><span style=display:flex><span>                        }
</span></span><span style=display:flex><span>                    }
</span></span><span style=display:flex><span>                ]
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>        ],
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;max_tokens&#34;</span>: <span style=color:#ae81ff>300</span>
</span></span><span style=display:flex><span>    });
</span></span></code></pre></div><p><a href=https://github.com/AugmendTech/cggui/blob/main/src-tauri/src/gptv.rs#L22>gptv.rs on GitHub</a></p><p>There&rsquo;s a lot more we could do here, like including the full chat history, but to keep things simple (and less expensive) we&rsquo;re just sending the current message along with an image of the currently shared application. But even in this simple form, it&rsquo;s surprisingly powerful!</p><h1 id=make-your-own>Make your own!</h1><p>The hardest part of this whole project was the screen capture. There seemed to be no good cross-platform libraries for screen capture, and this was a big hurdle for both this project and the products we want to build at Augmend. To solve this problem we created CrabGrab as an open source project. We&rsquo;re hoping this will make it much easier for other people to create similar projects. You can see a few other examples of CrabGrab in <a href=https://github.com/AugmendTech/CrabGrab/>the repo</a>. Try it out and let us know what you build!</p></div><div class=post-footer></div></article></main></body></html>